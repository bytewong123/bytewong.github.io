---
title: 缓存和DB数据的一致性
date: 2023-01-08T18:06:57+08:00
draft: false
categories: ["系统设计"]
tags: ["系统设计"]
---

# 缓存和DB数据的一致性
#技术/系统设计

## DB更新时，缓存应淘汰还是更新
**一般来说，是淘汰**。
* 一般来说，修改的成本会高于淘汰的成本 
	* 修改的话，假如存的是json字符串，需要先将数据反序列化，然后修改数据，然后序列化，再存入redis。修改的代价高，但是少一次cache miss
	* 淘汰的话，就将数据置为无效，但是多一次cache miss
* 修改缓存，在并发写的时候，可能出现数据不一致 
	* 比如说请求1 先写数据库，然后请求2写数据库
	* 接着请求2更新缓存，请求1更新缓存
	* 这就造成数据库是请求2的修改结果，缓存是请求1的修改结果
* 一般的模式为： 
	* 更新了数据，就直接淘汰掉缓存

## 顺序问题
是先操作缓存，还是先操作DB？
**先操作缓存，再操作DB**
先淘汰缓存成功，后更新DB失败（比如说服务挂了），不会造成不一致。
但是缓存淘汰了以后，主库还没有同步到从库，又有一个读请求，把旧的数据读到缓存，也会造成不一致。
这种情况下不一致概率是比较高的，因为一般情况下读请求远远高于写请求，当淘汰了缓存之后，在更新DB之前很有可能有读请求把从库的旧数据读到缓存中，从而造成不一致。
不过对于这种情况，有以下两种办法：
* 给缓存设置过期时间，能达到最终一致性
* 监听主库bin log，当主从同步完成，再淘汰一次缓存
但是这样子代价就比较高了，架构变得复杂。

**先操作DB，后操作缓存**
先更新DB，后更新缓存。
 假如更新完DB后，服务挂了，没有更新缓存，缓存过期后，经历一次缓存miss，那么数据将达到最终一致。

这种情况也可能出现不一致的情况：
1. 读请求b，发现缓存过期了
2. 读请求b读取db，读到旧值
3. 写请求a更新db
4. 写请求a删除缓存
5. b将之前读取到的数据库的值，回填到缓存中

这种情况发生的概率比较小，需要满足：
1. 缓存失效
2. 当读请求早于写请求
3. 读请求慢于写请求的操作流程
三个条件，才会发生。而正常情况下写请求比读请求慢得多得多

还有一种情况是，在并发环境下，Cache-Aside 中也存在读请求命中缓存的时间点在写请求更新数据库之后，删除缓存之前，这样也会导致读请求查询到的缓存落后于数据库的情况。

在 Cache-Aside 中也可能存在更新数据库成功，但删除缓存失败的场景，如果发生这种情况，那么便会导致缓存中的数据落后于数据库，产生数据的不一致的问题。
### 删除失败的补偿机制
1. 由于同步重试删除在性能上会影响吞吐量，所以常通过引入消息队列，将删除失败的缓存对应的 key 放入消息队列中，在对应的消费者中获取删除失败的 key ，异步重试删除。这种方法在实现上相对简单，但由于删除失败后的逻辑需要基于业务代码的 trigger 来触发 ，对业务代码具有一定入侵性。
2. 消费binlog，对Update操作进行缓存再删除，进一步补偿

item服务的缓存清理策略：
item服务是如果miss缓存了，则读db的从库
删除三次缓存
* 更新完db后，第1次删缓存：在于清理旧数据，触发未来读从。但是要是从没有准备好的话也白读。所以感觉价值不大。可能用于兜底删缓存2失败吧。
* 消费到binlog后，第2次删缓存：在大部分从都同步成功的情况下清理旧数据，未来有高概率读从读到最新。
* 消费到binlog后，第3次删缓存：兜底，提高最终一致的可能性。主要也是删缓存2不能覆盖所有的场景。

item用了三种存储
1. redis缓存
2. mysql存储
3. abase兜底，消费mysql的binlog写入abase

如何扩展redis
Item作为一个容量大流量大的服务，在缓存方面有非常大的需求。 单个Redis集群无法提供足够的容量。 为了做到对Redis的水平扩张，Item中构建了一个虚拟Redis集群的概念，用于屏蔽物理Redis集群。
1. 通过上游PSM获取对应的虚拟Redis集群
2. 通过Item Id 生成对应的缓存Key， 对缓存Key做crc16 hash， 然后根据Hash分片映射真实Redis Client
3. 如果是读操作，从获取的Redis Client 列表中随机获取一个，如果是写则全部使用（读一，写全）




## 延迟双删
延时双删即先删除缓存，然后更新数据，再延时一段时间后删除缓存。

为了保证第二次删除缓存的时间点在读请求更新缓存之后，这个延迟时间的经验值通常应稍大于业务中读请求的耗时。
延迟的实现可以在代码中 sleep 或采用延迟队列。显而易见的是，无论这个值如何预估，都很难和读请求的完成时间点准确衔接，这也是延时双删被诟病的主要原因。

1. 在修改数据库数据前，需要先删除一次 [redis](https://worktile.com/kb/tag/redis) ：此时是为了保证在数据库数据修改和redis数据被删除的间隔时间内，如有命中，保证此数据也不存在redis中。如果没有这一次删除，当数据库数据已经被修改了，但是还是可以从redis中读出旧数据，导致数据不一致。
2. 第二次删除则是在修改数据库数据后，此时需要再次删除redis中对应数据一次，这一次是为了删除 第一次redis删除和数据库数据修改之间，如果有请求，那么旧数据又会重新缓存到redis中，然而数据在数据库中在接下来就会被修改，如果没有这一次删除，redis中则会存在数据库中旧的数据。
3. 那么第二次为什么需要在数据库修改后延迟一定时间再删除redis呢？为了等待之前的一次读取数据库，并等待其数据写入到缓存，最后删除这次脏数据，所以是一次数据从数据库中发到服务器+缓存写入的时间



## Cache Aside Pattern
Cache Aside Pattern是缓存经典实践方式，分为读实践、写实践。
### **对于读请求**
* 先读缓存
* 缓存命中，直接返回数据
* 缓存未命中，则查询DB
* 将数据set到内存
### **对于写请求**
* 先更新数据库
* 后淘汰缓存（可以引入延迟，因为如果有主从同步的db，有可能下一次请求回源时，拿到的是还没有同步的旧值，将其更新到了缓存中）

## 热点缓存击穿
1. 热点数据永不过期
2. 使用分布式锁。如果缓存失效的情况，只有拿到锁才可以查询数据库，降低了在同一时刻打在数据库上的请求，防止数据库打死。当然这样会导致系统的性能变差。

## 并发回源问题
### 缓存的更新有两种方法:
* 被动更新：先从缓存获取，没有则回源获取，再更新缓存；
* 主动更新：发现数据改变后直接更新缓存（在分布式场景下，不容易实现）
在 [高并发](https://so.csdn.net/so/search?q=%E9%AB%98%E5%B9%B6%E5%8F%91&spm=1001.2101.3001.7020) 环境，被动回源是需要注意的。 问题：高并发场景下，大量请求在同一时间回源，大量的请求同一时间穿透到后端，容易引起后端服务崩溃（也容易引起并发问题）。

guava cache解决办法： guava cache保证单线程回源，对于同一个key，只让一个请求回源load，其他线程阻塞等待结果。同时，在Guava里可以通过配置expireAfterAccess/expireAfterWrite设定key的过期时间，key过期后就单线程回源加载并放回缓存。
这样通过Guava Cache简简单单就较为安全地实现了缓存的被动更新操作。

但是如果对于同一时间大量不同的key同时过期，造成大量不同的key同时回源，这种怎么解决呢？
guava cache实现类似ConcurrentHashMap，维护segment数组，每个segment独享一个锁，ConcurrentHashMap是通过这种机制来实现分段锁，ConcurrentHashMap默认分了16个segment； guava Cache默认是4个segment，故guava cache的并发级别默认是4个，也就是说默认情况下，即便是大量不同的key同时过期，最多只也有4个线程并发回源，理论上不会给后端造成过大的压力。

### guava refresh和expire刷新机制
* expireAfterAccess: 当缓存项在指定的时间段内没有被读或写就会被回收。
* expireAfterWrite：当缓存项在指定的时间段内没有更新就会被回收。
* refreshAfterWrite：当缓存项上一次更新操作之后的多久会被刷新。


